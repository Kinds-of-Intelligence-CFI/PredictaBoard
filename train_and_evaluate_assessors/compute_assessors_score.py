"""This script processes the raw results file obtained with the train assessors notebook/script to obtain performance metrics."""

import pandas as pd
import os
from scipy.integrate import simpson

from utils.general_utils import load_with_conditions

from typing import List, Tuple, Callable

short_labels_predictive_method = {
    'logistic_regression_l2': 'Logistic Regression (l2)',
    'logistic_regression_l1_c=1': 'Logistic Regression (l1)',
    'logistic_regression_l1_c=0.1': 'Logistic Regression (l1, c=0.1)',
    'xgboost': 'XGBoost',
}

short_labels_features = {
    'openai': 'OpenAI',
    'word2vec': 'Word2Vec',
    'fasttext': 'FastText',
    'ngrams_1': 'Ngrams-1',
    'fineTunedLlama': 'FT-Llama'
}


def get_PVR_for_threshold(threshold: float) -> Callable[[List[Tuple[float, float]]], float]:
    return lambda vals: 1 - min([rate for rate, acc in vals if acc >= threshold])


def area_under_ARC(x_y_points: List[Tuple[float, float]]) -> float:
    xs = [x for x, _ in x_y_points]
    ys = [y for _, y in x_y_points]
    return simpson(y=ys, x=xs)


# set file names
test_dataset_name_ID = "mmlu_pro"
filename_ID = os.path.join("results", "mmlu_pro_assessor_results_full.pkl")
csv_ID = "mmlu_pro_assessor_results.csv"
saved_figure_extension_ID = "_ID"

test_dataset_name_OOD = "bbh"
filename_OOD = os.path.join("results", "bbh_assessor_results_full.pkl")
csv_OOD = "bbh_assessor_results.csv"
saved_figure_extension_OOD = "_OOD"

train_dataset_name = "mmlu_pro"
PVR_thresholds = [0.8, 0.9, 0.95]

# Load results generated by train_embeddings_assessors.ipynb
assessors_results_df_ID = load_with_conditions(filename_ID)
assessors_results_df_OOD = load_with_conditions(filename_OOD)

for assessors_results_df, csv_extension in zip([assessors_results_df_ID, assessors_results_df_OOD], [csv_ID, csv_OOD]):
    # Remove l1_c=0.1 assessors, as the regularization seems to be too much (they normally become a constant assessor)
    assessors_results_df = assessors_results_df[
        assessors_results_df["predictive_method"] != "logistic_regression_l1_c=0.1"]

    print(f"Loaded number considered LLMs: {len(set(assessors_results_df_ID['llm']))}")
    print(f"Loaded number of LLM-assessor pairs: {len(assessors_results_df_ID)}")

    # replace the names with abbreviated versions
    assessors_results_df["predictive_method"] = assessors_results_df["predictive_method"].replace(
        short_labels_predictive_method)
    assessors_results_df["features"] = assessors_results_df["features"].replace(short_labels_features)

    # now sort them so that OAI, W2V, FT, NG1 are together
    # Define a custom order for embeddings
    feature_order = ['openai', 'word2vec', 'fasttext', 'ngrams_1']

    # Convert to a categorical type with the desired order
    assessors_results_df["feature_order"] = pd.Categorical(assessors_results_df["features"], categories=feature_order,
                                                           ordered=True)

    # Now sort by feature_order, and then by predictive method
    assessors_results_df = assessors_results_df.sort_values(["feature_order", "predictive_method"])

    for threshold in PVR_thresholds:
        PVR_col_name = f"{threshold} PVR"
        assessors_results_df[PVR_col_name] = assessors_results_df["arc_test"].apply(get_PVR_for_threshold(threshold))

    area_under_arc_col_name = "Area under\nARC"
    assessors_results_df[area_under_arc_col_name] = assessors_results_df["arc_test"].apply(area_under_ARC)

    # Add an llm_method_features name for each row
    assessors_results_df["pair_name"] = assessors_results_df.apply(
        lambda row: f"{row['llm'].replace('__', '/')}\n({row['predictive_method']}, {row['features']})", axis=1)
    # Add a method_features name for each row
    assessors_results_df["predictive_method_features"] = assessors_results_df.apply(
        lambda row: f"{row['predictive_method']}_{row['features']}", axis=1)

    # remove the columns that take a lot of space:
    assessors_results_df = assessors_results_df.drop(
        ["trained_classifier", 'predictions_train', 'predictions_val', 'predictions_test'], axis=1)

    # save to CSV
    assessors_results_df.to_csv("results/" + csv_extension)
